---
title: "brightspots"
author: "Christopher Rounds"
date: "10/16/2023"
output: html_document
---

```{r setup}
library(tidyverse)
library(mnsentinellakes)
library(arrow)
library(lme4)
library(sf)
library(mgcv)
library(rfUtilities)
library(pdp)
library(randomForest)
library(mwlaxeref)
source("rf_functions.r")

mn_data <- open_dataset("./data/mn_file_arrow/") 

mn_lakes <- readRDS("./data/covariate/mndow_lakes_sf_allDataUntransformed.rds")

adult_wae <- read.csv("./data/clean_data/wae_abundance.csv") %>% 
  mutate(lake_id = mnsentinellakes::fixlakeid(lake_id))

#Some of the NHD HR IDs are wonky fix them here
missing_ids <- data.frame(
  lake_id = c("69069400", "69060800", "38053200", "38021100", "16063300"), 
  nhdhr.id = c("nhdhr_120019354", "nhdhr_80993113", 
               "nhdhr_72d19d48-754d-459b-a1f2-b1cfd8993b06", "nhdhr_80993749", 
               "nhdhr_120019082"))
adult_wae = adult_wae %>% rows_update(y = missing_ids, by = c("lake_id"))
```


# Get gill net data from file
## Include gill nets that caught zero walleye
```{r}
# vector of walleye lake IDs
gn_lakes <- unique(adult_wae$lake_id)
gn_lakes_nhd <- unique(adult_wae$nhdhr.id)
# not the same number of lakes between them?
# Lakes missing nhd 16089700, 16089600, 16052800, 16034300



adult_wae %>%
  ggplot(aes(total_effort_1.1)) +
  geom_histogram(binwidth = 1)
```

# add physical lake data to gill net sureys
```{r}
mn_lakes <- readRDS("./data/covariate/mndow_lakes_sf_allDataUntransformed.rds")
sf_use_s2(FALSE) # we dont like spheres

st_crs(mn_lakes) <- 26915
mn_gn_lakes <- mn_lakes %>% dplyr::filter(dowlknum %in% gn_lakes)



mn_gn_lakes <- st_as_sf(x = mn_lakes,                         
                  coords = c("x", "y"),
                  crs = "+proj=utm +zone=15")
mn_gn_lakes = st_transform(mn_lakes, crs = "+proj=longlat +datum=WGS84")
mn_gn_lakes$x <- st_coordinates(st_centroid(st_as_sf(mn_gn_lakes)))[,"X"]
mn_gn_lakes$y <- st_coordinates(st_centroid(st_as_sf(mn_gn_lakes)))[,"Y"]

mn_gn_lakes_clean <- as.data.frame(mn_gn_lakes) %>% 
  select("dowlknum", "pw_basin_n","acres","wb_class", "shore_mi", "x", "y") %>%
  dplyr::filter(pw_basin_n != "Mississippi River - Pepin (WI)") %>%
  rename(lake_id = dowlknum) %>% distinct(lake_id, .keep_all = T) %>%
  # make sure some riverish lakes stay (lake pepin, laq que parle)
  mutate(wb_class = ifelse(lake_id == "25000100", 
                           "semiriverine polygon", wb_class),
         wb_class = ifelse(lake_id == "37004600", 
                           "semiriverine polygon", wb_class),
         wb_class = ifelse(lake_id == "62004700", 
                           "semiriverine polygon", wb_class),
         wb_class = ifelse(lake_id == "69129100", 
                           "semiriverine polygon", wb_class))

gn_spatial.nodepth <- merge(x = adult_wae, y = mn_gn_lakes_clean, 
                    by = "lake_id", all.x = T) %>%
  dplyr::filter(wb_class != "Riverine polygon")
# removes river gill netting

mn_depth <- read.csv("./data/lake_metadata.csv") %>% 
  dplyr::filter(site_id %in% gn_spatial.nodepth$nhdhr.id) %>%
  dplyr::select(site_id, max_depth, area, elevation) %>%
  rename(nhdhr.id = site_id)

gn_spatial <- merge(gn_spatial.nodepth, mn_depth, by = "nhdhr.id",
                      all.x = T)
```

# Add stocking data
```{r stocking_gn}
stocking <- read.csv("./data/covariate/mn_wae_stocking.csv") %>% 
  rename(lake_id = DOW, year = Year) %>% mutate(lake_id = fixlakeid(lake_id)) %>%
  mutate(lake_id = ifelse(lake_id == "04003500", "04003501", lake_id))

# add current year stocking
gn_stocking <- merge(x = gn_spatial, y = stocking, 
                         by = c("lake_id", "year"), all.x = T) %>%
  mutate(across(FRY:frl.pa, ~ ifelse(is.na(.), 0, .))) %>%
  mutate(julian_day = yday(date_clean))  %>%
  #If any are stocked make Stocked = 1
  mutate(STOCKED =  ifelse(rowSums(across(fry.pa:frl.pa)) > 0, 1, 0),
         fry.pa = FRY/acres, 
         fgl.pa = FGL/acres, 
         adl.pa = ADL/acres, 
         yrl.pa = YRL/acres,
         frl.pa = FRL/acres) %>%
  dplyr::select(-c(FRY:FRL))

# add previous year stocking

stocking.previous <- stocking %>% mutate(year = year + 1) %>%
  rename_with(~ paste(., ".previous", sep = ""), FRY:frl.pa)

gn_stocking <- merge(x = gn_stocking, y = stocking.previous, 
                         by = c("lake_id", "year"), all.x = T) %>%
  mutate(across(FRY.previous:frl.pa.previous, ~ ifelse(is.na(.), 0, .))) %>%
  #If any are stocked make Stocked = 1
  mutate(STOCKED.previous =  ifelse(rowSums(across(fry.pa.previous:frl.pa.previous)) > 0, 1, 0),
         fry.pa.previous = FRY.previous/acres, 
         fgl.pa.previous = FGL.previous/acres, 
         adl.pa.previous = ADL.previous/acres, 
         yrl.pa.previous = YRL.previous/acres,
         frl.pa.previous = FRL.previous/acres) %>%
  dplyr::select(-c(FRY.previous:FRL.previous))

# add two year ago stocking

stocking.2.previous <- stocking %>% mutate(year = year + 2) %>%
  rename_with(~ paste(., ".2.previous", sep = ""), FRY:frl.pa)

gn_stocking <- merge(x = gn_stocking, y = stocking.2.previous, 
                         by = c("lake_id", "year"), all.x = T) %>%
  mutate(across(FRY.2.previous:frl.pa.2.previous, ~ ifelse(is.na(.), 0, .))) %>%
  #If any are stocked make Stocked = 1
  mutate(STOCKED.2.previous =  ifelse(rowSums(across(fry.pa.2.previous:frl.pa.2.previous)) > 0, 1, 0),
         fry.pa.2.previous = FRY.2.previous/acres, 
         fgl.pa.2.previous = FGL.2.previous/acres, 
         adl.pa.2.previous = ADL.2.previous/acres, 
         yrl.pa.2.previous = YRL.2.previous/acres,
         frl.pa.2.previous = FRL.2.previous/acres) %>%
  dplyr::select(-c(FRY.2.previous:FRL.2.previous))
```


# Add remotely sensed Secchi data to gill net surveys
```{r gn_secchi}
secchi <- read.csv("./data/covariate/MN_AnnualSecchi_update.csv") %>%
  select(year, median_secchi, Prmnn_I) %>%
  mutate(nhdhr.id = paste0("nhdhr_", Prmnn_I))


nhd.id <- mwlaxeref::lake_id_xref %>% filter(state == "mn") %>%
  mutate(local.id = fixlakeid(local.id)) %>%
  group_by(local.id, nhdhr.id) %>% distinct(.keep_all = T) %>% ungroup()

secchi.full = merge(x = secchi, y = nhd.id, 
               by = c("nhdhr.id"), all.x = T) %>%
  select(local.id, nhdhr.id, lagos.id, year, median_secchi) %>%
  rename(lake_id = local.id) %>%
  group_by(lake_id, nhdhr.id, year) %>% 
  distinct(.keep_all = T) %>% ungroup() %>%
  dplyr::select(lake_id, year, median_secchi) %>%
  mutate(secchi.source = "RS")

# add remotely sensed secchi to the gill net data
gn_secchi <- merge(x = gn_stocking, y = secchi.full, 
                   by = c("lake_id", "year"), all.x = T)

secchi.prior <- secchi.full %>% mutate(year = year + 1) %>%
  rename(median_secchi_previous = median_secchi) %>%
  mutate(secchi.source.prior = "RS") %>%
  dplyr::select(lake_id, year, median_secchi_previous, secchi.source.prior)

gn_secchi <- merge(x = gn_secchi, y = secchi.prior, 
                   by = c("lake_id", "year"), all.x = T)

secchi.2.prior <- secchi.full %>% mutate(year = year + 2) %>%
  rename(median_secchi_previous_2 = median_secchi) %>%
  dplyr::select(lake_id, year, median_secchi_previous_2) %>%
  mutate(secchi.source.2 = "RS")

gn_secchi <- merge(x = gn_secchi, y = secchi.2.prior, 
                   by = c("lake_id", "year"), all.x = T)
```

# Add in KV secchi 
```{r}
kv_surveys <- function(offset = 0){
  
  if (offset == 0){
    # Which Secchis are we missing? (when we have 3+ years of surveys)
    na_secchi <- gn_secchi %>% dplyr::filter(is.na(median_secchi)) %>%
      group_by(lake_id) %>% count() %>% filter(n >= 3) 
    # select those surveys
    missing_secchi <- gn_secchi %>% dplyr::filter(is.na(median_secchi)) %>%
      filter(year < 2019) %>%
      filter(lake_id %in% na_secchi$lake_id) %>% dplyr::select(year, lake_id)
  }
  
  if (offset == 1){
    # Which Secchis are we missing? (when we have 3+ years of surveys)
    na_secchi <- gn_secchi %>% dplyr::filter(is.na(median_secchi_previous)) %>%
      group_by(lake_id) %>% count() %>% filter(n >= 3)
    # select those surveys
    missing_secchi <-  gn_secchi %>% dplyr::filter(is.na(median_secchi_previous)) %>%
      filter(year < 2019) %>%
      filter(lake_id %in% na_secchi$lake_id) %>% dplyr::select(year, lake_id)
  }

  if (offset == 2){
    # Which Secchis are we missing? (when we have 3+ years of surveys)
    na_secchi <- gn_secchi %>% dplyr::filter(is.na(median_secchi_previous_2)) %>%
      group_by(lake_id) %>% count() %>% filter(n >= 3) 
    # select those surveys
    missing_secchi <-  gn_secchi %>% dplyr::filter(is.na(median_secchi_previous_2)) %>%
      filter(year < 2019) %>%
      filter(lake_id %in% na_secchi$lake_id) %>% dplyr::select(year, lake_id)
  }
  
  # what surveys does Kelsey have that we are missing?
  secchi_file_list <- list.files("./data/Secchi_Predictions/")
  
  matching_kv_secchi <- missing_secchi %>% 
    filter(missing_secchi$lake_id %in% substr(secchi_file_list, 1, 8))
    
  # read in those observations and calculate median Secchi
  matching_kv_secchi$median_secchi <- -999
  
  for (i in 1:nrow(matching_kv_secchi)) {
    dow <- matching_kv_secchi$lake_id[i]
    survey_year <- matching_kv_secchi$year[i] + offset
    secchi_temp <- readRDS(paste0("./data/Secchi_Predictions/", dow, 
                                  "_daily_secchi.rds"))
    filter_secchi_temp <- secchi_temp %>% 
      filter(Year == survey_year) %>% filter(DOY > 150, DOY < 300) 
    matching_kv_secchi$median_secchi[i] <- median(filter_secchi_temp$Fit, na.rm = T)
  }
  
  matching_kv_secchi <- matching_kv_secchi %>% distinct(lake_id, year, median_secchi) %>% 
    mutate(secchi.source = "KV")
  
  if (offset == 1){
    colnames(matching_kv_secchi) = c("lake_id", "year", "median_secchi_previous", "secchi.source.prior")
  }
  if (offset == 2){
    colnames(matching_kv_secchi) = c("lake_id", "year", "median_secchi_previous_2", "secchi.source.2")
  }
  gn_secchi <- gn_secchi %>% 
    rows_update(y = matching_kv_secchi, by = c("year", "lake_id"))
  
  return(gn_secchi)
}

gn_secchi <- kv_surveys(offset = 0)
gn_secchi <- kv_surveys(offset = 1)
gn_secchi <- kv_surveys(offset = 2)

missing_secchi <-  gn_secchi %>% filter(is.na(median_secchi)) %>% group_by(lake_id) %>% count
```

#remove secchi stuff
```{r}
rm(secchi); rm(missing_secchi); rm(na_secchi)
rm(secchi_temp); rm(secchi.full)
rm(secchi.prior); rm(secchi.2.prior); rm(missing_ids)
```


# collect and add AIS data
```{r gn_ais, warning=FALSE}
ais <- readxl::read_excel("./data/covariate/infested-waters.xlsx") %>% 
  dplyr::filter(ais == "zebra mussel") %>% select(!Column1) %>%
  dplyr::filter(dow != "NA", dow != "na") %>%
  dplyr::filter(!grepl("none", dow) ) %>%
  mutate(lake_id = fixlakeid(dow),
         lake_id = str_pad(lake_id, width = 8, side = "right", pad = "0")) %>%
  dplyr::rename(year.listed = year) %>%
  select(lake_id, year.listed, year_confirmed, ais)


#BACI - 1 = infested lake before infestation
#BACI - 2 = Infested lake post infestation
#BACI - 3 = uninfested lake pre-pseudo year
#BACI - 4 = uninfested lake post pseudo year
gn_ais <- merge(x = gn_secchi, y = ais, 
                         by = "lake_id", all.x = T) %>%
  mutate(ais = ifelse(is.na(ais), 0, 1),
         year_confirmed = as.numeric(year_confirmed),
         year_confirmed = ifelse(is.na(year_confirmed), NA, year_confirmed),
         infested = ifelse(year_confirmed <= year, 1, 0),
         BACI = ifelse(year_confirmed >= year, 1, 0),
         BACI = ifelse(infested == 1, 2, BACI),
         BACI = ifelse(is.na(BACI), 3, BACI),
         BACI = ifelse(BACI == 3 & year > 2016, 4, BACI)) %>%
  dplyr::select(!c(year.listed, ais))
```

# temperature metrics
```{r}

current_temps <- read_feather(
  "./data/lake_temperature_metrics_GLM_NLDAS.feather") %>% 
  dplyr::select(site_id, year, peak_temp, ice_off_date, 
                winter_dur_0_4, coef_var_1_30, coef_var_31_60,
                gdd_wtr_0c, gdd_wtr_5c, gdd_wtr_10c, contains("mean_surf"),
                post_ice_warm_rate, contains("date_over")) %>% 
  rename(nhdhr.id = site_id)

  
# add temp data from prior year 
gn_temp <- merge(gn_ais, current_temps, 
                 by = c("year", "nhdhr.id"), all.x = T) %>%
  dplyr::filter(effort_ident != 36874)

temp.previous <- current_temps %>% mutate(year = year + 1) %>%
  rename_with(~ paste(., ".previous", sep = ""), peak_temp:date_over_21)

gn_temp <- merge(gn_temp, temp.previous, 
                 by = c("year", "nhdhr.id"), all.x = T)

# add temp data from 2 years prior
temp.2.previous <- current_temps %>% mutate(year = year + 2) %>%
  rename_with(~ paste(., ".2.previous", sep = ""), peak_temp:date_over_21)

gn_temp <- merge(gn_temp, temp.2.previous, 
                 by = c("year", "nhdhr.id"), all.x = T)

gn_temp_na <- gn_temp %>% 
  filter(is.na(peak_temp)) %>% 
  filter(year != 2022) %>% group_by(nhdhr.id) %>%
  count() %>% filter(n > 2)
```

# remove unnesseccary objects
```{r}
rm(current_temps); rm(gn_stocking); rm(gn_ais); rm(gn_spatial); rm(mn_lakes); 
rm(adult_wae); rm(mn_gn_lakes); rm(mn_gn_lakes_clean);  rm(ais)
rm(stocking); rm(stocking.previous); rm(stocking.2.previous)
rm(temp.previous); rm(temp.2.previous); rm(nhd.id); rm(gn_secchi)
```

# output data
```{r}
gn_temp_clean <- gn_temp %>%
  dplyr::filter(year >= 1988) %>%
  mutate(year_f = as.factor(year),
         log_acres = log(acres),
         log_shore_mi = log(shore_mi),
         ice_off_jday = yday(ice_off_date)
         )

three.years <- gn_temp_clean %>% group_by(lake_id) %>% count() %>% 
  filter(n >= 3)
  

gn_temp_train <- gn_temp_clean %>%
  dplyr::filter(lake_id %in% three.years$lake_id) %>%
  mutate(lake_id = as.numeric(lake_id), 
         STOCKED = as.factor(STOCKED),
         BACI = as.factor(BACI)) %>%
  select(c("lake_id", "lake_name.1", "x", "y", "cpue", "count", "total_effort_1.1",
           "year","julian_day", "cpue_yep","cpue_cisco", "cpue_np", 
           "log_acres", "log_shore_mi", "elevation", "max_depth", "BACI", 
           fry.pa:STOCKED.2.previous,
           "median_secchi", "median_secchi_previous", "median_secchi_previous_2",
           peak_temp:date_over_21.2.previous)) %>% 
  #filter(is.na(median_secchi))
  group_by(lake_id) %>% 
  mutate(across(where(is.numeric), ~replace_na(., median(., na.rm=TRUE)))) %>%
  ungroup() %>% filter(!is.na(median_secchi))
write.csv(gn_temp_train, "./data/adult_catch_data.csv", row.names = F)

#ex <- gn_temp %>% filter(lake_id == "39000200") %>% select(1:15) 

#write.csv(ex, "multi_survey_ex.csv", row.names = F)
```


# random plotting
```{r}
all_wae_gn %>% group_by(year) %>% count() %>%
  ggplot() +
  geom_point(aes(y = n, x = year))


range(wae.gn$julianday)


# from mid march - mid december

wae.gn %>% 
  dplyr::filter(year > 1980) %>%
  dplyr::filter(julianday > 150, julianday < 275) %>%
  ggplot(aes(y = cpue, x = julianday)) +
  #geom_point() +
  geom_smooth(method = "gam")
```

